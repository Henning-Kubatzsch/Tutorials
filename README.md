# From Zero to Hero â€“ Reimplementation Projects

This repository contains my personal reimplementations of Andrej Karpathy's excellent **"Neural Networks: Zero to Hero"** tutorial series.

The goal of these projects is to deepen my understanding of core concepts in machine learning, including automatic differentiation, neural network training, and transformer-based language models.

## Included Projects

- `micrograd`: a minimal autograd engine
- `makemore`: a character-level language model
- `nanoGPT` (optional): small GPT reimplementation

## Motivation

All code was written from scratch by me, following the tutorial videos, and includes:

- My own comments and explanations
- Additional experiments, tweaks, and debugging
- Insights and clarifications that helped me understand the inner workings

These projects are **not meant to showcase original algorithms**, but to demonstrate my commitment to mastering foundational ML/NLP concepts through hands-on coding.

## Attribution

The original tutorials and reference code were created by [Andrej Karpathy](https://github.com/karpathy).  
Original license: MIT.

## License

This repository is shared under the MIT License.
